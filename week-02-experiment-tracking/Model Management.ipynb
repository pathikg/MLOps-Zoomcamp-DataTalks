{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652244ad",
   "metadata": {},
   "source": [
    "# ðŸ’¼ Model Management ðŸ’¼ \n",
    "Well seems like you've learnt to do so**Machine Learning Experiments** with **Experiment-Tracking** and after doing experiments you've found some models which you would like to use but how do you **store** them? How to keep track of versions of those models? Do we really need a versioning system for our models ?\n",
    "\n",
    "<img src=\"https://c.tenor.com/XHyzk7O2ndIAAAAS/what-meme.gif\" alt=\"how\" width=\"200\"></img>\n",
    "\n",
    "## Lets find out ðŸ”Ž\n",
    "\n",
    "From your ML Experiment, lets say you got bunch of models trained on a bit different distributions of datasets, hyperparameters, optimizers, etc. and you just store them manually one by one in each folder  \n",
    "something like this :\n",
    "\n",
    "![folder_struct](./images/folder_struct.jpg)\n",
    "\n",
    "(btw this is how I usually store my models ðŸ˜‰)\n",
    "\n",
    "and you just manually add more if you want ...\n",
    "\n",
    "Hmmmm there's a bit of a problem here ðŸ¤”\n",
    "\n",
    "* There's no consistency in the naming\n",
    "* No track of model version\n",
    "* No track of training-validation data used\n",
    "* Visually kinda seems a bit messy :(\n",
    "\n",
    "This might not be that of a big issue for a small projects like your school/college projects but for companies and startups this is indeed a big problem as those ML systems needs to be continously monitored and retrained to be able to adapt to the behaviour of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103eee0e",
   "metadata": {},
   "source": [
    "# Model Management with MLFlow ðŸ¤–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9a911",
   "metadata": {},
   "source": [
    "Continuing from [previous](./mlflow-experiment-tracking-intro.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8550881",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9698b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b3d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/1', experiment_id='1', lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d8ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a26ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('./data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('./data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38462ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e66bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6a5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683e62f",
   "metadata": {},
   "source": [
    "# How to log models? ðŸ“’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9305d0",
   "metadata": {},
   "source": [
    "## Using `log_artifact()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ed509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:40] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:19.48425\n",
      "[1]\tvalidation-rmse:17.95634\n",
      "[2]\tvalidation-rmse:16.59114\n",
      "[3]\tvalidation-rmse:15.37412\n",
      "[4]\tvalidation-rmse:14.29011\n",
      "[5]\tvalidation-rmse:13.32800\n",
      "[6]\tvalidation-rmse:12.47570\n",
      "[7]\tvalidation-rmse:11.72140\n",
      "[8]\tvalidation-rmse:11.05888\n",
      "[9]\tvalidation-rmse:10.47583\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() :\n",
    "    mlflow.set_tag(\"tutorial\", \"management\")\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=10,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    booster.save_model(\"models/xgb_model.json\")\n",
    "    \n",
    "    # tracking model using log_artifact i.e. save model present \n",
    "    # at location `local_path` to `artifact_path` present in each run's artifact URI\n",
    "    mlflow.log_artifact(local_path=\"models/xgb_model.json\", artifact_path=\"mlflow_model\")\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb614c3",
   "metadata": {},
   "source": [
    "If you visit your MLFlow UI for the current run then you will see your model stored in the run's artifact URI which can be accessed later \n",
    "![log_artifact_op](./images/log_artifact_op.jpg)\n",
    "\n",
    "Okay so ,\n",
    "* Models are getting saved automatically in each run\n",
    "* Saved with information about hyperparameters\n",
    "* Saved model can be accessed and downloaded later  \n",
    "\n",
    "but what if we have to share this to someone who doesn't have any idea about versions of packages used in our current project ?\n",
    "\n",
    "![another option](https://www.memecreator.org/static/images/memes/5217550.jpg)\n",
    "\n",
    "## Using `log_model()`\n",
    "(specific to each framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9445a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:40] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation-rmse:19.48425\n",
      "[1]\tvalidation-rmse:17.95634\n",
      "[2]\tvalidation-rmse:16.59114\n",
      "[3]\tvalidation-rmse:15.37412\n",
      "[4]\tvalidation-rmse:14.29011\n",
      "[5]\tvalidation-rmse:13.32800\n",
      "[6]\tvalidation-rmse:12.47570\n",
      "[7]\tvalidation-rmse:11.72140\n",
      "[8]\tvalidation-rmse:11.05888\n",
      "[9]\tvalidation-rmse:10.47583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathikx/miniconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() :\n",
    "    mlflow.set_tag(\"tutorial\", \"management\")\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=10,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # tracking model using log_model\n",
    "    mlflow.xgboost.log_model(booster, artifact_path=\"mlflow_model\")\n",
    "    # simple han ?\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482eef7",
   "metadata": {},
   "source": [
    "If you check this run then with the information about logged parameters and metric you will also see information about your envionment and packages used in the artifact section\n",
    "\n",
    "![log_model_op1](./images/log_model_op1.jpg)\n",
    "\n",
    "It also provides a snippets on how to load the model and make predictions \n",
    "![log_model_op2.jpg](./images/log_model_op2.jpg)\n",
    "\n",
    "Conda environment info :\n",
    "![log_model_op3.jpg](./images/log_model_op3.jpg)\n",
    "\n",
    "and so on...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6923966",
   "metadata": {},
   "source": [
    "Well looks like we are able to store the models in each runs with all the information about different logged parameters such as `hyperparameters`, `metrics`, `dependencies`, etc. but still we haven't figured out a way for model versioning right ?  \n",
    "well that's where **Model Registry** comes in which we will learn in next notebook\n",
    "\n",
    "See ya then \n",
    "\n",
    "![thanks](https://c.tenor.com/35hmBwYHYikAAAAM/the-office-bow.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
